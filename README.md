# EF-PPO
EF-PPO implementation of Leonard Franz

## Install and run
In python >=3.10, <=3.11.5 run..
```
pip install ef-ppo
```

Download [sagittal_walk.yaml](experiments/sagittal_walk.yaml) and run the following at the file location:
```
python -m deprl.main --path sagittal_walk.yaml
```
