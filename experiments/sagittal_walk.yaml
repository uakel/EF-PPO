DEP:
  bias_rate: 0.002
  buffer_size: 200
  intervention_length: 5
  intervention_proba: 0.0004
  kappa: 1169.7
  normalization: independent
  q_norm_selector: l2
  regularization: 32
  s4avg: 2
  sensor_delay: 1
  tau: 40
  test_episode_every: 3
  time_dist: 5
  with_learning: true
env_args: {}
id: 0
tonic:
  after_training: '' 
  header: "import deprl, gym, myosuite, gait-40-dof-22-musc-sagittal, torch, efppo"
  agent: '
  deprl.custom_agents.dep_factory(6, efppo.ef_ppo.EF_PPO())(
    replay=efppo.hl_segment.HLSegment(
      size=512,
      discount_factor=0.99,
      trace_decay=0.9,
      batch_size=128,
      h_term_penalty=1.8,
      l_term_penalty=2.7
    ), 
    model=efppo.models.HLActorCritic(
      actor=deprl.vendor.tonic.torch.models.Actor(
        encoder=deprl.vendor.tonic.torch.models.ObservationEncoder(),
        torso=deprl.vendor.tonic.torch.models.MLP((256, 256), torch.nn.ReLU),
        head=deprl.vendor.tonic.torch.models.DetachedScaleGaussianPolicyHead(),
      ),
      l_critic=deprl.vendor.tonic.torch.models.Critic(
        encoder=deprl.vendor.tonic.torch.models.ObservationEncoder(),
        torso=deprl.vendor.tonic.torch.models.MLP((256, 256), torch.nn.ReLU),
        head=deprl.vendor.tonic.torch.models.ValueHead(),
      ), 
      h_critic=deprl.vendor.tonic.torch.models.Critic(
        encoder=deprl.vendor.tonic.torch.models.ObservationEncoder(),
        torso=deprl.vendor.tonic.torch.models.MLP((256, 256), torch.nn.ReLU),
        head=deprl.vendor.tonic.torch.models.ValueHead(),
      ), 
      observation_normalizer=deprl.vendor.tonic.torch.normalizers.MeanStd(), 
    ), 
    actor_updater=deprl.vendor.tonic.torch.updaters.actors.ClippedRatio(
      optimizer=lambda params: torch.optim.Adam(params, lr=3e-5),
      entropy_coeff=0.001,
      ratio_clip=0.20 
    ), 
    h_critic_updater=efppo.updaters.critics.VRegression(
      optimizer=lambda params: torch.optim.Adam(params, lr=4e-5),
    ),
    l_critic_updater=efppo.updaters.critics.VRegression(
      optimizer=lambda params: torch.optim.Adam(params, lr=4e-5),
    ),
  )'
  before_training: ''
  checkpoint: last
  environment: deprl.environments.Gym('gait_40_dof_22_musc_sagittal-v0', scaled_actions=False, reset_type='random')
  full_save: 0
  name: ef_ppo_test
  parallel: 12
  resume: 1
  seed: 0
  sequential: 4
  test_environment: null
  trainer: "efppo.ef_ppo_trainer.Trainer(
    steps=int(1e8),
    epoch_steps=int(3 * 12e3),
    save_steps=int(3 * 6e4),
    test_episodes=10,
    discount=0.99,
    constraint_function=lambda observations, muscle_states: 
        np.abs(observations[:, 39].flatten() * 100 - 1.2) - 0.1
    ,
    max_budget=2.7
  )"
working_dir: .
